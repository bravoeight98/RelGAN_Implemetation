{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RelGAN_master_implemetation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO8FEHDIS51PhFTxKNOjjH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bravoeight98/RelGAN_Implemetation/blob/main/RelGAN_master_implemetation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMfZRMS0q1TF"
      },
      "source": [
        "Preprocesing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjgu83cvlVjD"
      },
      "source": [
        "# Copyright (C) 2019 Willy Po-Wei Wu & Elvis Yu-Jing Lin <maya6282@gmail.com, elvisyjlin@gmail.com>\n",
        "# \n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"-n\", \"--number\", type=int, default=17, help=\"attribute number\")\n",
        "parser.add_argument(\"-o\", \"--output\", type=str, default='anno_dic.npy', help=\"output file\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "annos = open('list_attr_celeba.txt').readlines()\n",
        "\n",
        "attrs = str.split(annos[1])\n",
        "print(attrs)\n",
        "\n",
        "if args.number == 17:\n",
        "    new_attrs = ['5_o_Clock_Shadow', 'Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Male', 'Mustache', 'Pale_Skin', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Hat', 'Young']\n",
        "elif  args.number == 9:\n",
        "    new_attrs = ['Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Mustache', 'Pale_Skin', 'Smiling', 'Young']\n",
        "elif  args.number == 5:\n",
        "    new_attrs = ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
        "else:\n",
        "    print('You can only choose 17, 9, 5  combination')\n",
        "    exit()\n",
        "\n",
        "new_attrs_index = []\n",
        "for x in new_attrs:\n",
        "    new_attrs_index.append(attrs.index(x))\n",
        "print(new_attrs_index)\n",
        "\n",
        "annosAry = {}\n",
        "for i in range(2,len(annos)):\n",
        "    anno = str.split(annos[i])\n",
        "    temp = [(int(i)+1)/2 for i in anno[1:]]\n",
        "    temp2 = []\n",
        "    for ii in new_attrs_index:\n",
        "        temp2.append(temp[ii])\n",
        "    annosAry[anno[0]] = temp2\n",
        "    \n",
        "print(annosAry[\"000001.jpg\"])\n",
        "print(len(annosAry[\"000001.jpg\"]))\n",
        "\n",
        "np.save(args.output, annosAry)\n",
        "\n",
        "img_list = open('image_list.txt').readlines()\n",
        "imgIndex = [None]*len(img_list)\n",
        "\n",
        "for i in range(1,len(img_list)):\n",
        "    temp = str.split(img_list[i])\n",
        "    imgIndex[int(temp[0])] = temp[2]\n",
        "    \n",
        "print(imgIndex[29999])\n",
        "\n",
        "np.save(\"imgIndex.npy\", imgIndex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNpEvr71q7c1"
      },
      "source": [
        "RelGAN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kpW1EZjisBE"
      },
      "source": [
        "# Copyright (C) 2019 Willy Po-Wei Wu & Elvis Yu-Jing Lin <maya6282@gmail.com, elvisyjlin@gmail.com>\n",
        "#\n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras import backend as K\n",
        "from keras.utils import plot_model\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from module import *\n",
        "from ops import *\n",
        "from skimage import io, transform\n",
        "from tensorboardX import SummaryWriter\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "class Relgan():\n",
        "\n",
        "    def __init__(self, args):\n",
        "\n",
        "        self.path = args.path\n",
        "        self.lr = args.lr\n",
        "        self.b1 = args.beta1\n",
        "        self.b2 = args.beta2\n",
        "        self.batch = args.batch_size\n",
        "        self.sample = args.sample_size\n",
        "        self.epochs = args.epochs\n",
        "        self.lambda1 = args.lambda1\n",
        "        self.lambda2 = args.lambda2\n",
        "        self.lambda4 = args.lambda4\n",
        "        self.lambda5 = args.lambda5\n",
        "        self.gp_l = args.lambda_gp\n",
        "        self.decay = self.lr / self.epochs\n",
        "        self.imgSize = args.img_size\n",
        "        self.sampleSize = args.img_size\n",
        "        self.vecSize = args.vec_size\n",
        "        self.step = args.step * 200\n",
        "\n",
        "        self.lr -= self.decay * self.step\n",
        "\n",
        "        self.img_shape = (self.imgSize, self.imgSize, 3)\n",
        "        self.vec_shape = (self.vecSize,)\n",
        "\n",
        "        self.get_model()\n",
        "        self.get_loss()\n",
        "        self.get_optimizer()\n",
        "        self.datagen = ImageDataGenerator(horizontal_flip=True)\n",
        "        self.writer = SummaryWriter()\n",
        "\n",
        "    def get_model(self):\n",
        "\n",
        "        self.imgA_input = Input(shape=self.img_shape)\n",
        "        self.imgB_input = Input(shape=self.img_shape)\n",
        "        self.vec_input_pos = Input(shape=self.vec_shape)\n",
        "        self.vec_input_neg = Input(shape=self.vec_shape)\n",
        "\n",
        "        g_out = generator(self.imgA_input, self.vec_input_pos, self.imgSize)\n",
        "\n",
        "        self.g_model = Model(inputs=[self.imgA_input, self.vec_input_pos], outputs=g_out)\n",
        "\n",
        "        d_out = discriminator(self.imgA_input, self.imgB_input, self.vec_input_pos, self.imgSize, self.vecSize)\n",
        "\n",
        "        self.d_model = Model(inputs=[self.imgA_input, self.imgB_input, self.vec_input_pos], \\\n",
        "                             outputs=d_out)\n",
        "\n",
        "        print(self.g_model.summary())\n",
        "        print(self.d_model.summary())\n",
        "\n",
        "        plot_model(self.g_model, to_file='g_model.png')\n",
        "        plot_model(self.d_model, to_file='d_model.png')\n",
        "\n",
        "    def get_loss(self):\n",
        "\n",
        "        def cal_df_gp():\n",
        "\n",
        "            def cal_gp(gradients):\n",
        "                gradients_sqr = K.square(gradients[0])\n",
        "                gradients_sqr_sum = K.sum(gradients_sqr, axis=np.arange(1, len(gradients_sqr.shape)))\n",
        "                gradient_l2_norm = K.sqrt(gradients_sqr_sum)\n",
        "                gradient_penalty = K.mean(K.square(1 - gradient_l2_norm))\n",
        "                return gradient_penalty\n",
        "\n",
        "            alpha = K.random_uniform_variable(shape=(1,), low=0, high=1)\n",
        "\n",
        "            mix_tar = alpha * self.img_a + (1 - alpha) * self.img_a2b\n",
        "\n",
        "            mix_outputs_a2b = self.d_model([self.img_a, mix_tar, self.vec_ab_pos])\n",
        "            mix_outputs_a2ab = self.d_model([self.img_a, self.img_a2ab, self.vec_ab_pos])\n",
        "\n",
        "            gradients_a2b = K.gradients([mix_outputs_a2b[0]], [mix_tar])\n",
        "            gradients_a2ab = K.gradients([mix_outputs_a2ab[2]], [self.img_a2ab])\n",
        "\n",
        "            df_gp = cal_gp(gradients_a2b) + cal_gp(gradients_a2ab)\n",
        "\n",
        "            return df_gp\n",
        "\n",
        "        def lsgan(xs, ts):\n",
        "            real = 0\n",
        "            fake = 0\n",
        "            for i in range(len(xs)):\n",
        "                if ts[i] == 1:\n",
        "                    real += K.mean(K.square(K.ones_like(xs[i]) - xs[i]), axis=[-1])\n",
        "                else:\n",
        "                    fake += K.mean(K.square(K.zeros_like(xs[i]) - xs[i]), axis=[-1])\n",
        "\n",
        "            return real + fake\n",
        "\n",
        "        self.img_a = Input(shape=self.img_shape)\n",
        "        self.img_b = Input(shape=self.img_shape)\n",
        "        self.img_c = Input(shape=self.img_shape)\n",
        "\n",
        "        self.vec_ab_pos = Input(shape=self.vec_shape)\n",
        "        self.vec_ac_pos = Input(shape=self.vec_shape)\n",
        "        self.vec_cb_pos = Input(shape=self.vec_shape)\n",
        "\n",
        "        self.img_a2b, self.enc_a2b = self.g_model([self.img_a, self.vec_ab_pos])\n",
        "        self.img_a2a, self.enc_a2a = self.g_model([self.img_a, K.zeros_like(self.vec_ab_pos)])\n",
        "        self.img_a2b2a, _ = self.g_model([self.img_a2b, -self.vec_ab_pos])\n",
        "\n",
        "        inter_seed = K.random_uniform_variable(shape=([self.batch, ]), low=0, high=1)\n",
        "        inter_seed = K.reshape(inter_seed, [self.batch, 1])\n",
        "        self.img_a2ab, self.enc_a2ab = self.g_model([self.img_a, inter_seed * self.vec_ab_pos])\n",
        "\n",
        "        input_real = [self.img_a, self.img_b, self.vec_ab_pos]\n",
        "        input_fake = [self.img_a, self.img_a2b, self.vec_ab_pos]\n",
        "        input_w_ori = [self.img_c, self.img_b, self.vec_ab_pos]\n",
        "        input_w_tar = [self.img_a, self.img_c, self.vec_ab_pos]\n",
        "        input_w_vec1 = [self.img_a, self.img_b, self.vec_ac_pos]\n",
        "        input_w_vec2 = [self.img_a, self.img_b, self.vec_cb_pos]\n",
        "\n",
        "        input_inter = [self.img_a, self.img_a2ab, inter_seed * self.vec_ab_pos]\n",
        "        input_zero = [self.img_a, self.img_a2a, K.zeros_like(self.vec_ab_pos)]\n",
        "\n",
        "        d_real, dc_real, _ = self.d_model(input_real)\n",
        "\n",
        "        d_fake, dc_fake, di_fake = self.d_model(input_fake)\n",
        "\n",
        "        d_w_ori, dc_w_ori, _ = self.d_model(input_w_ori)\n",
        "        d_w_tar, dc_w_tar, _ = self.d_model(input_w_tar)\n",
        "        d_w_vec1, dc_w_vec1, _ = self.d_model(input_w_vec1)\n",
        "        d_w_vec2, dc_w_vec2, _ = self.d_model(input_w_vec2)\n",
        "\n",
        "        _, _, di_inter = self.d_model(input_inter)\n",
        "        _, _, di_zero = self.d_model(input_zero)\n",
        "\n",
        "        self.df_loss = lsgan([d_real, d_fake], [1, 0])\n",
        "        self.dc_loss = lsgan([dc_real, dc_fake, dc_w_ori, dc_w_tar, dc_w_vec1, dc_w_vec2], [1, 0, 0, 0, 0, 0])\n",
        "        inter_seed_rep = K.flatten(inter_seed)\n",
        "\n",
        "        di_temp = K.switch(K.less(inter_seed_rep, 0.5 * K.ones_like(inter_seed_rep)), di_zero, di_fake)\n",
        "\n",
        "        self.di_loss = K.square(K.minimum(inter_seed_rep, K.ones_like(inter_seed_rep) - inter_seed_rep) * K.ones_like(\n",
        "            di_inter) - di_inter) + K.square(di_temp)\n",
        "        print('self.df_loss', K.int_shape(self.df_loss))\n",
        "        print('self.dc_loss', K.int_shape(self.dc_loss))\n",
        "        print('self.di_loss', K.int_shape(self.di_loss))\n",
        "\n",
        "        self.df_gp = cal_df_gp()\n",
        "\n",
        "        self.d_loss = self.df_loss + self.dc_loss + self.gp_l * self.df_gp + self.lambda5 * self.di_loss\n",
        "\n",
        "        self.gf_loss = lsgan([d_real, d_fake], [0, 1])\n",
        "        self.gc_loss = lsgan([dc_real, dc_fake], [0, 1])\n",
        "        self.gi_loss = K.square(di_inter)\n",
        "\n",
        "        dist_a2b = self.enc_a2b - self.enc_a2a\n",
        "        dist_a2ab = self.enc_a2ab - self.enc_a2a\n",
        "\n",
        "        inter_seed = K.reshape(inter_seed, [self.batch, 1, 1, 1])\n",
        "        self.g_inter_loss = K.mean(K.abs(inter_seed * dist_a2b - dist_a2ab))\n",
        "\n",
        "        g_loss_rec1 = K.mean(K.abs(self.img_a - self.img_a2b2a))\n",
        "        g_loss_rec2 = K.mean(K.abs(self.img_a - self.img_a2a))\n",
        "\n",
        "        print('self.gf_loss', K.int_shape(self.gf_loss))\n",
        "        print('self.gc_loss', K.int_shape(self.gc_loss))\n",
        "        print('self.gi_loss', K.int_shape(self.gi_loss))\n",
        "        print('self.g_loss_rec1', K.int_shape(g_loss_rec1))\n",
        "        print('self.g_loss_rec2', K.int_shape(g_loss_rec2))\n",
        "\n",
        "        self.gr_loss = self.lambda1 * g_loss_rec1 + self.lambda2 * g_loss_rec2\n",
        "        self.g_loss = self.gf_loss + self.gc_loss + self.gr_loss + self.lambda5 * self.gi_loss\n",
        "\n",
        "    def get_optimizer(self):\n",
        "\n",
        "        g_opt = Adam(lr=self.lr, decay=self.decay, beta_1=self.b1, beta_2=self.b2)\n",
        "        g_weights = self.g_model.trainable_weights\n",
        "        g_inputs = [self.img_a, self.img_b, self.vec_ab_pos]\n",
        "\n",
        "        self.g_training_updates = g_opt.get_updates(g_weights, [], self.g_loss)\n",
        "        self.g_train = K.function(g_inputs,\n",
        "                                  [K.mean(self.g_loss),\n",
        "                                   K.mean(self.gf_loss),\n",
        "                                   K.mean(self.gc_loss),\n",
        "                                   K.mean(self.gr_loss),\n",
        "                                   K.mean(self.g_inter_loss),\n",
        "                                   K.mean(self.gi_loss)],\n",
        "                                  self.g_training_updates)\n",
        "\n",
        "        d_opt = Adam(lr=self.lr, decay=self.decay, beta_1=self.b1, beta_2=self.b2)\n",
        "        d_weights = self.d_model.trainable_weights\n",
        "        d_inputs = [self.img_a, self.img_b, self.img_c, self.vec_ab_pos, self.vec_ac_pos, self.vec_cb_pos]\n",
        "\n",
        "        self.d_training_updates = d_opt.get_updates(d_weights, [], self.d_loss)\n",
        "        self.d_train = K.function(d_inputs,\n",
        "                                  [K.mean(self.d_loss),\n",
        "                                   K.mean(self.df_loss),\n",
        "                                   K.mean(self.dc_loss),\n",
        "                                   K.mean(self.gp_l * self.df_gp),\n",
        "                                   K.mean(self.di_loss)],\n",
        "                                  self.d_training_updates)\n",
        "\n",
        "    def get_imgs_tags(self, indexserX, imgIndex, imgAttr):\n",
        "        imgs = [None] * self.batch\n",
        "        atts = [None] * self.batch\n",
        "\n",
        "        for i in range(self.batch):\n",
        "            temp_index = indexserX[i]\n",
        "        #    temp_index = int(re.sub(\"\\D\", \"\", temp_index ))\n",
        "            print(temp_index)\n",
        "            x = np.where(imgIndex == temp_index)\n",
        "            print(x)\n",
        "            print(indexserX[i])                        #\n",
        "            img_fa = imgIndex[int(x[0])]\n",
        "\n",
        "      #      while img_fa == None:\n",
        "       #         temp_index = np.random.choice((imgIndex), 1)[0]    #\n",
        "        #        img_fa = imgIndex[temp_index]\n",
        "            atts[i] = imgAttr[img_fa]\n",
        "            print(temp_index)                                           #\n",
        "            img = io.imread(os.path.join(self.path, str(temp_index).zfill(10)))\n",
        "            imgs[i] = img / 127.5 - 1\n",
        "\n",
        "        imgs = np.array(imgs)\n",
        "        atts = np.array(atts)\n",
        "\n",
        "        self.datagen.fit(imgs)\n",
        "\n",
        "        imgs = self.datagen.flow(imgs, batch_size=self.batch, shuffle=False).next()\n",
        "\n",
        "        return imgs, atts\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        print(\"load index\")\n",
        "        imgIndex = np.load(\"imgIndex.npy\")\n",
        "        imgAttr = np.load(\"anno_dic.npy\").item()\n",
        "        print(\"training\")\n",
        "\n",
        "        ite = self.step\n",
        "\n",
        "        def getIndex():\n",
        "            while True:\n",
        "                count = 0\n",
        "                index_permutation = np.random.permutation((imgIndex))     #\n",
        "                while count + self.batch * 3 < len(imgIndex):\n",
        "                    yield index_permutation[count:(count + self.batch * 3)]\n",
        "                    count = count + self.batch * 3\n",
        "\n",
        "        index_gen = getIndex()\n",
        "\n",
        "        def get_training_data(wrong=False):\n",
        "            indexser = next(index_gen)\n",
        "            indexser1 = indexser[self.batch * 0:self.batch * 1]\n",
        "            indexser2 = indexser[self.batch * 1:self.batch * 2]\n",
        "            indexser3 = indexser[self.batch * 2:self.batch * 3]\n",
        "\n",
        "            img_as, att_as = self.get_imgs_tags(indexser1, imgIndex, imgAttr)\n",
        "            img_bs, att_bs = self.get_imgs_tags(indexser2, imgIndex, imgAttr)\n",
        "            vec_ab_pos = att_bs - att_as\n",
        "\n",
        "            if wrong == False:\n",
        "                return img_as, img_bs, vec_ab_pos\n",
        "\n",
        "            img_cs, att_cs = self.get_imgs_tags(indexser3, imgIndex, imgAttr)\n",
        "\n",
        "            vec_ac_pos = att_cs - att_as\n",
        "            vec_cb_pos = att_bs - att_cs\n",
        "\n",
        "            return img_as, img_bs, img_cs, vec_ab_pos, vec_ac_pos, vec_cb_pos\n",
        "\n",
        "        for ep in range(int(self.epochs)):\n",
        "\n",
        "            t_start = time.time()\n",
        "\n",
        "            img_as, img_bs, img_cs, vec_ab_pos, vec_ac_pos, vec_cb_pos = get_training_data(wrong=True)\n",
        "\n",
        "            for i in range(1):\n",
        "                errD = self.d_train([img_as, img_bs, img_cs, vec_ab_pos, vec_ac_pos, vec_cb_pos])\n",
        "\n",
        "            for i in range(1):\n",
        "                errG = self.g_train([img_as, img_bs, vec_ab_pos])\n",
        "\n",
        "            t_end = time.time()\n",
        "\n",
        "            print(\n",
        "                \"%9.6f %9.6f | real: %7.4f wrong: %7.4f gp: %7.4f| fake: %7.4f wrong: %7.4f recs: %7.4f enc: %7.4f| time: %.4f\" % (\n",
        "                errD[0], errG[0], errD[1], errD[2], errD[3], errG[1], errG[2], errG[3], errG[4], t_end - t_start))\n",
        "\n",
        "            self.writer.add_scalar('d_loss', errD[0], ite)\n",
        "            self.writer.add_scalar('g_loss', errG[0], ite)\n",
        "            self.writer.add_scalar('df_loss', errD[1], ite)\n",
        "            self.writer.add_scalar('gf_loss', errG[1], ite)\n",
        "            self.writer.add_scalar('dc_loss', errD[2], ite)\n",
        "            self.writer.add_scalar('gc_loss', errG[2], ite)\n",
        "            self.writer.add_scalar('gr_loss', errG[3], ite)\n",
        "            self.writer.add_scalar('inter_loss', errG[4], ite)\n",
        "            self.writer.add_scalar('gp_loss', errD[3], ite)\n",
        "            self.writer.add_scalar('gi_loss', errG[5], ite)\n",
        "            self.writer.add_scalar('di_loss', errD[4], ite)\n",
        "\n",
        "            if ite % 50 == 0 and ite > 0:\n",
        "\n",
        "                img_as, img_bs, vec_ab_pos = get_training_data(wrong=False)\n",
        "\n",
        "                g_a2b = [img_as[:self.sample], vec_ab_pos[:self.sample]]\n",
        "                fakea2b, _ = self.g_model.predict(g_a2b)\n",
        "\n",
        "                g_a2a = [img_as[:self.sample], np.zeros([self.sample, self.vecSize])]\n",
        "                fakea2a, _ = self.g_model.predict(g_a2a)\n",
        "\n",
        "                g_a2b2a = [fakea2b[:self.sample], -vec_ab_pos[:self.sample]]\n",
        "                fakea2b2a, _ = self.g_model.predict(g_a2b2a)\n",
        "\n",
        "                images = np.concatenate([img_as[:self.sample], fakea2b, fakea2b2a, fakea2a], axis=0)\n",
        "\n",
        "                width = self.sample\n",
        "                height = 4\n",
        "                new_im = Image.new('RGB', (self.sampleSize * height, self.sampleSize * width))\n",
        "                for ii in range(height):\n",
        "                    for jj in range(width):\n",
        "                        index = ii * width + jj\n",
        "                        image = (images[index] / 2 + 0.5) * 255\n",
        "                        image = transform.resize(image, (self.sampleSize, self.sampleSize), preserve_range=True)\n",
        "                        #                         image = image*255\n",
        "                        image = image.astype(np.uint8)\n",
        "                        new_im.paste(Image.fromarray(image, \"RGB\"), (self.sampleSize * ii, self.sampleSize * jj))\n",
        "                filename = \"img/fakeFace%d.jpg\" % (ite // 200)\n",
        "                new_im.save(filename)\n",
        "\n",
        "                try:\n",
        "                    self.g_model.save(\"model/generator%d.h5\" % (ite // 200))\n",
        "                    self.d_model.save(\"model/discriminator.h5\")\n",
        "                except:\n",
        "                    print('Pass save')\n",
        "            ite = ite + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hlhjsovrAAq"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBzgOvNWkIkc"
      },
      "source": [
        "# Copyright (C) 2019 Willy Po-Wei Wu & Elvis Yu-Jing Lin <maya6282@gmail.com, elvisyjlin@gmail.com>\n",
        "# \n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"-p\", \"--path\", type=str, default='E:\\Current_Sem_Project\\CSE465\\Dataset\\celeba-hq\\celeba-256', help=\"data path\")\n",
        "parser.add_argument(\"-d\", \"--device\", type=str, default='1', help=\"gpu device\")\n",
        "parser.add_argument(\"-g\", \"--growth\", type=bool, default=False, help=\"allow_growth\")\n",
        "parser.add_argument(\"-s\", \"--step\", type=int, default=0, help=\"train_step\")\n",
        "parser.add_argument(\"-l\", \"--lr\", type=float, default=5e-5)\n",
        "parser.add_argument(\"-b1\", \"--beta1\", type=float, default=0.5)\n",
        "parser.add_argument(\"-b2\", \"--beta2\", type=float, default=0.999)\n",
        "parser.add_argument(\"-batch\", \"--batch_size\", type=int, default=4)\n",
        "parser.add_argument(\"-sample\", \"--sample_size\", type=int, default=2)\n",
        "parser.add_argument(\"-ep\", \"--epochs\", type=int, default=400000)\n",
        "parser.add_argument(\"-l1\", \"--lambda1\", type=int, default=10)\n",
        "parser.add_argument(\"-l2\", \"--lambda2\", type=int, default=10)\n",
        "parser.add_argument(\"-l4\", \"--lambda4\", type=int, default=10)\n",
        "parser.add_argument(\"-l5\", \"--lambda5\", type=int, default=10)\n",
        "parser.add_argument(\"-gp\", \"--lambda_gp\", type=int, default=150)\n",
        "parser.add_argument(\"-img\", \"--img_size\", type=int, default=256)\n",
        "parser.add_argument(\"-v\", \"--vec_size\", type=int, default=17)\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "\n",
        "from relgan import Relgan\n",
        "\n",
        "# K.set_floatx('float64')\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "set_session(tf.compat.v1.Session(config=config))\n",
        "\n",
        "rel_gan = Relgan(args)\n",
        "rel_gan.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULvx3yyFr2MH"
      },
      "source": [
        "DemoTranslation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaOeBbqpscC_"
      },
      "source": [
        "# Copyright (C) 2019 Willy Po-Wei Wu & Elvis Yu-Jing Lin <maya6282@gmail.com, elvisyjlin@gmail.com>\n",
        "# \n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from skimage import io, transform\n",
        "from keras.models import load_model\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from contrib.ops import SwitchNormalization\n",
        "from module import *\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"-d\", \"--device\", type=str, default='0')\n",
        "args = parser.parse_args()\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "set_session(tf.Session(config=config))\n",
        "\n",
        "def tileAttr(x):\n",
        "    x = tf.expand_dims(x, axis = 1)\n",
        "    x = tf.expand_dims(x, axis = 2)\n",
        "    return tf.tile(x, [1, 256, 256, 1])\n",
        "\n",
        "def tileAttr2(x):\n",
        "        x = tf.expand_dims(x, axis = 1)\n",
        "        x = tf.expand_dims(x, axis = 2)\n",
        "        return tf.tile(x, [1, 4, 4, 1])\n",
        "    \n",
        "# train_path = '/share/diskB/willy/GanExample/FaceAttributeChange_StarGAN/model/generator499.h5'\n",
        "\n",
        "def testPic(img, gender, bangs=-1, glasses=1):\n",
        "    temp3 = io.imread(img)\n",
        "    tempb = transform.resize(temp3, [256,256])\n",
        "    tempb = tempb[:,:,:3]\n",
        "    tempb = tempb*2 - 1\n",
        "    \n",
        "    # imgIndex = np.load(\"imgIndex.npy\")\n",
        "# imgAttr = np.load(\"anno_dic.npy\").item()\n",
        "\n",
        "    new_attrs = ['5_o_Clock_Shadow', 'Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Male', 'Mustache', 'Pale_Skin', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Hat', 'Young']\n",
        "\n",
        "    def att2vec(attt):\n",
        "        temp_vec = np.expand_dims(attt, axis=0)\n",
        "        return temp_vec\n",
        "\n",
        "    attrs_pos, attrs_neg = [],[]\n",
        "    attr = []\n",
        "    \n",
        "    temp = np.zeros([17])\n",
        "    # temp[new_attrs.index('Brown_Hair')] = -1\n",
        "    temp[new_attrs.index('Black_Hair')] = -1\n",
        "    temp[new_attrs.index('Blond_Hair')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Black_Hair')] = -1\n",
        "    # temp[new_attrs.index('Brown_Hair')] = -1\n",
        "    # temp[new_attrs.index('Black_Hair')] = 1\n",
        "    temp[new_attrs.index('Brown_Hair')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    if gender==1:\n",
        "        temp[new_attrs.index('Male')] = -1\n",
        "    else:\n",
        "        temp[new_attrs.index('Male')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    #if gender==0:\n",
        "    temp[new_attrs.index('Male')] = 1 \n",
        "    temp[new_attrs.index('Goatee')] = 1\n",
        "    temp[new_attrs.index('Mustache')] = 1\n",
        "    temp[new_attrs.index('5_o_Clock_Shadow')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Pale_Skin')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Smiling')] = 1\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Bangs')] = bangs\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Eyeglasses')] = glasses\n",
        "    attr.append(temp)\n",
        "\n",
        "    temp = np.zeros([17])\n",
        "    temp[new_attrs.index('Gray_Hair')] = 1\n",
        "    temp[new_attrs.index('Young')] = -1\n",
        "    attr.append(temp)\n",
        "    \n",
        "    for at in attr:\n",
        "        att_pos = att2vec(at)\n",
        "        attrs_pos.append(att_pos)\n",
        "\n",
        "    attrs_pos = np.concatenate(attrs_pos, axis=0)    \n",
        "    \n",
        "    output = np.expand_dims(tempb, axis=0)\n",
        "    output2 = np.tile(output, [len(attr), 1, 1, 1])\n",
        "    outputs_, _ = relGan.predict([output2, attrs_pos])\n",
        "    images = np.concatenate([output, outputs_], axis = 0)\n",
        "    width = 1\n",
        "    height = len(attr) + 1\n",
        "    new_im = Image.new('RGB', (256*height, 256*width))\n",
        "    for ii in range(height):\n",
        "        for jj in range(width):\n",
        "            index=ii*width+jj\n",
        "            image = (images[index]/2+0.5)*255\n",
        "            image = image.astype(np.uint8)\n",
        "            new_im.paste(Image.fromarray(image,\"RGB\"), (256*ii,256*jj))\n",
        "    ans = np.array(new_im)\n",
        "    return ans\n",
        "\n",
        "# temp3 = io.imread('/share/data/celeba-hq/celeba-256/12345.jpg')\n",
        "# version = int(sys.argv[2])\n",
        "# if version==-1:\n",
        "#     version = len(os.listdir('img'))-2\n",
        "version = 519\n",
        "\n",
        "print(version)\n",
        "\n",
        "train_path = './generator'+str(version)+'.h5'\n",
        "#train_path = 'model/generator1511.h5'\n",
        "\n",
        "# train_path = 'good_v0513.h5'\n",
        "\n",
        "def orthogonal(w):\n",
        "    \n",
        "    w_kw = K.int_shape(w)[0]\n",
        "    w_kh = K.int_shape(w)[1]\n",
        "    w_w = K.int_shape(w)[2]\n",
        "    w_h = K.int_shape(w)[3]\n",
        "    \n",
        "    temp = 0\n",
        "    for i in range(w_kw):\n",
        "        for j in range(w_kh):\n",
        "            wwt = tf.matmul(tf.transpose(w[i,j]), w[i,j])\n",
        "            mi = K.ones_like(wwt) - K.identity(wwt)\n",
        "            a = wwt * mi\n",
        "            a = tf.matmul(tf.transpose(a), a)\n",
        "            a = a * K.identity(a)\n",
        "            temp += K.sum(a)\n",
        "    return 1e-4 * temp\n",
        "\n",
        "img_shape = (256, 256, 3)\n",
        "vec_shape = (17,)\n",
        "\n",
        "imgA_input = Input(shape=img_shape)\n",
        "imgB_input = Input(shape=img_shape)\n",
        "vec_input_pos = Input(shape=vec_shape)\n",
        "vec_input_neg = Input(shape=vec_shape)\n",
        "\n",
        "g_out = generator(imgA_input, vec_input_pos, 256)\n",
        "relGan = Model(inputs=[imgA_input, vec_input_pos], outputs=g_out)\n",
        "relGan.load_weights(train_path)\n",
        "relGan.summary()\n",
        "\n",
        "lengh = 10\n",
        "temp = [None]*lengh\n",
        "temp[0] = testPic('test_img/j.png',0)\n",
        "temp[1] = testPic('test_img/c.2.jpg',0)\n",
        "temp[2] = testPic('test_img/es.png',1)\n",
        "temp[3] = testPic('test_img/e.2.png',1)\n",
        "temp[4] = testPic('test_img/g.2.png',1)\n",
        "temp[5] = testPic('test_img/y3.png',1)\n",
        "temp[6] = testPic('test_img/f1.png',1,glasses=-1)\n",
        "temp[7] = testPic('test_img/j1.png',0,glasses=-1)\n",
        "temp[8] = testPic('test_img/c3.png',0)\n",
        "temp[9] = testPic('test_img/g3.png',1,glasses=-1)\n",
        "\n",
        "new_im = Image.new('RGB', (256*10, 256*lengh))\n",
        "for jj in tqdm(range(lengh)):\n",
        "    index = jj\n",
        "    image = temp[index]\n",
        "    new_im.paste(Image.fromarray(image,\"RGB\"), (0,256*jj))\n",
        "new_im.save('test_v%04d.jpg'%version)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx2Z1xu9uYnh"
      },
      "source": [
        "Demo Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOiiLj0LueXg"
      },
      "source": [
        "# Copyright (C) 2019 Willy Po-Wei Wu & Elvis Yu-Jing Lin <maya6282@gmail.com, elvisyjlin@gmail.com>\n",
        "# \n",
        "# This work is licensed under the Creative Commons Attribution-NonCommercial\n",
        "# 4.0 International License. To view a copy of this license, visit\n",
        "# http://creativecommons.org/licenses/by-nc/4.0/ or send a letter to\n",
        "# Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import imageio\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from skimage import io, transform\n",
        "from keras.models import load_model\n",
        "from keras.backend.tensorflow_backend import set_session\n",
        "from contrib.ops import SwitchNormalization\n",
        "from module import *\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"-d\", \"--device\", type=str, default='0')\n",
        "parser.add_argument(\"-f\", \"--file\", type=str, default='test_img/y3.png')\n",
        "parser.add_argument(\"-o\", \"--output\", type=str, default='output.gif')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.device\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "set_session(tf.Session(config=config))\n",
        "\n",
        "def tileAttr(x):\n",
        "    x = tf.expand_dims(x, axis = 1)\n",
        "    x = tf.expand_dims(x, axis = 2)\n",
        "    return tf.tile(x, [1, 256, 256, 1])\n",
        "\n",
        "def tileAttr2(x):\n",
        "        x = tf.expand_dims(x, axis = 1)\n",
        "        x = tf.expand_dims(x, axis = 2)\n",
        "        return tf.tile(x, [1, 4, 4, 1])\n",
        "\n",
        "# train_path = '/share/diskB/willy/GanExample/FaceAttributeChange_StarGAN/model/generator499.h5'\n",
        "\n",
        "def testPic(img, gender, bangs=-1, glasses=1):\n",
        "    temp3 = io.imread(img)\n",
        "    tempb = transform.resize(temp3, [256,256])\n",
        "    tempb = tempb[:,:,:3]\n",
        "    tempb = tempb*2 - 1\n",
        "    \n",
        "    # imgIndex = np.load(\"imgIndex.npy\")\n",
        "# imgAttr = np.load(\"anno_dic.npy\").item()\n",
        "\n",
        "    new_attrs = ['5_o_Clock_Shadow', 'Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Male', 'Mustache', 'Pale_Skin', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Hat', 'Young']\n",
        "\n",
        "    def att2vec(attt):\n",
        "        temp_vec = np.expand_dims(attt, axis=0)\n",
        "        return temp_vec\n",
        "\n",
        "    attrs_pos, attrs_neg = [],[]\n",
        "    attr = []\n",
        " \n",
        "    for i in range(0,21):\n",
        "        temp = np.zeros([17])\n",
        "        \n",
        "        temp[new_attrs.index('Smiling')] = 0.05 * i\n",
        "        #temp[new_attrs.index('Gray_Hair')] = 0.07* i\n",
        "        #temp[new_attrs.index('Young')] = -0.07* i\n",
        "        attr.append(temp)\n",
        "        \n",
        "    for i in range(21,0,-1):\n",
        "        temp = np.zeros([17])\n",
        "        \n",
        "        temp[new_attrs.index('Smiling')] = 0.05 * i\n",
        "        #temp[new_attrs.index('Gray_Hair')] = 0.07* i\n",
        "        #temp[new_attrs.index('Young')] = -0.07* i\n",
        "        attr.append(temp)\n",
        "        \n",
        "    for at in attr:\n",
        "        att_pos = att2vec(at)\n",
        "        attrs_pos.append(att_pos)\n",
        "\n",
        "    attrs_pos = np.concatenate(attrs_pos, axis=0)    \n",
        "    \n",
        "    output = np.expand_dims(tempb, axis=0)\n",
        "    output2 = np.tile(output, [len(attr), 1, 1, 1])\n",
        "    outputs_, _ = relGan.predict([output2, attrs_pos])\n",
        "    outputs_ = np.ndarray.astype((outputs_/2+0.5)*255, np.uint8)\n",
        "    imageio.mimsave('simple_'+args.output, outputs_[10:31])\n",
        "    imageio.mimsave(args.output, outputs_)\n",
        "\n",
        "# temp3 = io.imread('/share/data/celeba-hq/celeba-256/12345.jpg')\n",
        "version = 519\n",
        "#version = 461\n",
        "\n",
        "train_path = './generator'+str(version)+'.h5'\n",
        "\n",
        "print('version: ', version)\n",
        "#train_path = 'model/generator1511.h5'\n",
        "\n",
        "# train_path = 'good_v0513.h5'\n",
        "\n",
        "img_shape = (256, 256, 3)\n",
        "vec_shape = (17,)\n",
        "\n",
        "imgA_input = Input(shape=img_shape)\n",
        "imgB_input = Input(shape=img_shape)\n",
        "vec_input_pos = Input(shape=vec_shape)\n",
        "vec_input_neg = Input(shape=vec_shape)\n",
        "\n",
        "g_out = generator(imgA_input, vec_input_pos, 256)\n",
        "relGan = Model(inputs=[imgA_input, vec_input_pos], outputs=g_out)\n",
        "relGan.load_weights(train_path)\n",
        "relGan.summary()\n",
        "\n",
        "lengh = 1\n",
        "temp = [None]*lengh\n",
        "temp[0] = testPic(args.file, 1, glasses=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}